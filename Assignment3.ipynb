{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import Image\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "# adjust dimensions of plot area to make it look better\n",
    "plt.rcParams['figure.figsize'] = (15, 7)\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import papermill as pm\n",
    "from random import randint\n",
    "from sklearn.metrics import f1_score\n",
    "from statistics import mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data(filepath):\n",
    "    dataset = []\n",
    "    f = open(filepath)\n",
    "    for line in f.readlines():\n",
    "        edited_line = line.strip().replace('\\'', '').lower()\n",
    "        example = []\n",
    "        example.append(edited_line[:-1].strip())\n",
    "        example.append(int(edited_line[-1]))\n",
    "        dataset.append(example)\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nExtracting training datasets for Yelp and IMDB\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Extracting training datasets for Yelp and IMDB\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "yelp_train = extract_data('./hwk3_datasets/yelp-train.txt')\n",
    "imdb_train = extract_data('./hwk3_datasets/IMDB-train.txt')\n",
    "\n",
    "yelp_valid = extract_data('./hwk3_datasets/yelp-valid.txt')\n",
    "imdb_valid = extract_data('./hwk3_datasets/IMDB-valid.txt')\n",
    "\n",
    "yelp_test = extract_data('./hwk3_datasets/yelp-test.txt')\n",
    "imdb_test = extract_data('./hwk3_datasets/IMDB-test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nMaking dataframes for the train, valid and test sets of Yelp and IMDB\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Making dataframes for the train, valid and test sets of Yelp and IMDB\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "yelp_columns = ['review', 'rating']\n",
    "imdb_columns = ['review', 'sentiment']\n",
    "\n",
    "yelp_train_df = pd.DataFrame(data=yelp_train, columns=yelp_columns)\n",
    "imdb_train_df = pd.DataFrame(data=imdb_train, columns=imdb_columns)\n",
    "\n",
    "yelp_valid_df = pd.DataFrame(data=yelp_valid, columns=yelp_columns)\n",
    "imdb_valid_df = pd.DataFrame(data=imdb_valid, columns=imdb_columns)\n",
    "\n",
    "yelp_test_df = pd.DataFrame(data=yelp_test, columns=yelp_columns)\n",
    "imdb_test_df = pd.DataFrame(data=imdb_test, columns=imdb_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nStoring the input (reviews) for the\\ntrain, valid and test sets of Yelp and IMDB\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Storing the input (reviews) for the\n",
    "train, valid and test sets of Yelp and IMDB\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "yelp_train_input = list(yelp_train_df['review'])\n",
    "imdb_train_input = list(imdb_train_df['review'])\n",
    "\n",
    "yelp_valid_input = list(yelp_valid_df['review'])\n",
    "imdb_valid_input = list(imdb_valid_df['review'])\n",
    "\n",
    "yelp_test_input = list(yelp_test_df['review'])\n",
    "imdb_test_input = list(imdb_test_df['review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nStoring the rating (Yelp) and sentiment (IMDB)\\nfor the train, valid and test sets of Yelp and IMDB\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Storing the rating (Yelp) and sentiment (IMDB)\n",
    "for the train, valid and test sets of Yelp and IMDB\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "yelp_train_output = list(yelp_train_df['rating'])\n",
    "imdb_train_output = list(imdb_train_df['sentiment'])\n",
    "\n",
    "yelp_valid_output = list(yelp_valid_df['rating'])\n",
    "imdb_valid_output = list(imdb_valid_df['sentiment'])\n",
    "\n",
    "yelp_test_output = list(yelp_test_df['rating'])\n",
    "imdb_test_output = list(imdb_test_df['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nUsing a CountVectorizer will turn the\\nwords into lowercase and remove the punctuations\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Using a CountVectorizer will turn the\n",
    "words into lowercase and remove the punctuations\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "yelp_vectorizer = CountVectorizer()\n",
    "yelp_vectors_train = yelp_vectorizer.fit_transform(yelp_train_input)\n",
    "\n",
    "imdb_vectorizer = CountVectorizer()\n",
    "imdb_vectors_train = imdb_vectorizer.fit_transform(imdb_train_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nGet the frequency of the\\nwords in a vocabulary.\\n\\nReturn: A dictionary\\nwhich has the structure - \\n    key = word\\n    value = [id, count]\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Get the frequency of the\n",
    "words in a vocabulary.\n",
    "\n",
    "Return: A dictionary\n",
    "which has the structure - \n",
    "    key = word\n",
    "    value = [id, count]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vocab_frequencies(dataset_input, dataset_vectorizer):\n",
    "    word_id_count = {}\n",
    "    for example in dataset_input:\n",
    "        words = example.split()\n",
    "        for word in words:\n",
    "            if word in dataset_vectorizer.vocabulary_:\n",
    "                if word not in word_id_count:\n",
    "                    word_id_count[word] = [dataset_vectorizer.vocabulary_[word], 1]\n",
    "                else:\n",
    "                    word_id_count[word][1] += 1\n",
    "\n",
    "    return word_id_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "yelp_train_frequencies = get_vocab_frequencies(yelp_train_input, yelp_vectorizer)\n",
    "imdb_train_frequencies = get_vocab_frequencies(imdb_train_input, imdb_vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nSorting the words in the dictionary\\nin descending order of frequencies.\\nGetting the top 10,000 words (words\\nwith the highest frequencies). These\\nwords form the feature set.\\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Sorting the words in the dictionary\n",
    "in descending order of frequencies.\n",
    "Getting the top 10,000 words (words\n",
    "with the highest frequencies). These\n",
    "words form the feature set.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "yelp_feature_set = sorted(yelp_train_frequencies.items(), key=lambda kv: kv[1][1], reverse=True)[:10000]\n",
    "imdb_feature_set = sorted(imdb_train_frequencies.items(), key=lambda kv: kv[1][1], reverse=True)[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nBinary Bag-of-Words Representation:-\\n\\nMaking a new vectorizer for Yelp and IMDB.\\nThe new vectorizer is based on the 10,000\\nwords with the highest frequencies.\\n\\nTransform the valid and test input according\\nto the vectorizer just found. Convert the result\\ninto an array. Modify the array such that the\\nvalue along a dimension gets set to 1 if its\\nvalue is greater than zero else it gets set to 0.\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Binary Bag-of-Words Representation:-\n",
    "\n",
    "Making a new vectorizer for Yelp and IMDB.\n",
    "The new vectorizer is based on the 10,000\n",
    "words with the highest frequencies.\n",
    "\n",
    "Transform the valid and test input according\n",
    "to the vectorizer just found. Convert the result\n",
    "into an array. Modify the array such that the\n",
    "value along a dimension gets set to 1 if its\n",
    "value is greater than zero else it gets set to 0.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "yelp_vectorizer_final_binary = CountVectorizer()\n",
    "yelp_temp_df = pd.DataFrame(data=yelp_feature_set, columns=[\"word\", \"id_and_count\"])\n",
    "yelp_vectors_train_final_binary = yelp_vectorizer_final_binary.fit_transform(list(yelp_temp_df[\"word\"]))\n",
    "yelp_vectors_train_final_binary = (yelp_vectors_train_final_binary.toarray() > 0).astype(int)\n",
    "\n",
    "yelp_valid_temp1 = yelp_vectorizer_final_binary.transform(yelp_valid_input).toarray()\n",
    "yelp_vectors_valid_binary = (yelp_valid_temp1 > 0).astype(int)\n",
    "\n",
    "yelp_test_temp1 = yelp_vectorizer_final_binary.transform(yelp_test_input).toarray()\n",
    "yelp_vectors_test_binary = (yelp_test_temp1 > 0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_vectorizer_final_binary = CountVectorizer()\n",
    "imdb_temp_df = pd.DataFrame(data=imdb_feature_set, columns=[\"word\", \"id_and_count\"])\n",
    "imdb_vectors_train_final_binary = imdb_vectorizer_final_binary.fit_transform(list(imdb_temp_df[\"word\"]))\n",
    "imdb_vectors_train_final_binary = (imdb_vectors_train_final_binary.toarray() > 0).astype(int)\n",
    "\n",
    "imdb_valid_temp1 = imdb_vectorizer_final_binary.transform(imdb_valid_input).toarray()\n",
    "imdb_vectors_valid_binary = (imdb_valid_temp1 > 0).astype(int)\n",
    "\n",
    "imdb_test_temp1 = imdb_vectorizer_final_binary.transform(imdb_test_input).toarray()\n",
    "imdb_vectors_test_binary = (imdb_test_temp1 > 0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nFrequency Bag-of-Words representation\\n'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Frequency Bag-of-Words representation\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_frequency_array(arr):\n",
    "    for i in range(len(arr)):\n",
    "        example_sum = arr[i].sum()\n",
    "        if example_sum != 0:\n",
    "            arr[i] = arr[i]/example_sum\n",
    "    \n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "yelp_vectorizer_final_frequency = CountVectorizer()\n",
    "yelp_vectors_train_final_frequency = yelp_vectorizer_final_frequency.fit_transform(list(yelp_temp_df[\"word\"]))\n",
    "yelp_vectors_train_final_frequency = make_frequency_array(yelp_vectors_train_final_frequency.toarray().astype(float))\n",
    "\n",
    "yelp_valid_temp2 = yelp_vectorizer_final_frequency.transform(yelp_valid_input).toarray()\n",
    "yelp_vectors_valid_frequency = make_frequency_array(yelp_valid_temp2.astype(float))\n",
    "\n",
    "yelp_test_temp2 = yelp_vectorizer_final_frequency.transform(yelp_test_input).toarray()\n",
    "yelp_vectors_test_frequency = make_frequency_array(yelp_test_temp2.astype(float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_vectorizer_final_frequency = CountVectorizer()\n",
    "imdb_vectors_train_final_frequency = imdb_vectorizer_final_frequency.fit_transform(list(imdb_temp_df[\"word\"]))\n",
    "imdb_vectors_train_final_frequency = make_frequency_array(imdb_vectors_train_final_frequency.toarray().astype(float))\n",
    "\n",
    "imdb_valid_temp2 = imdb_vectorizer_final_frequency.transform(imdb_valid_input).toarray()\n",
    "imdb_vectors_valid_frequency = make_frequency_array(imdb_valid_temp2.astype(float))\n",
    "\n",
    "imdb_test_temp2 = imdb_vectorizer_final_frequency.transform(imdb_test_input).toarray()\n",
    "imdb_vectors_test_frequency = make_frequency_array(imdb_test_temp2.astype(float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nGenerating the data files\\nfor the submission\\n'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Generating the data files\n",
    "for the submission\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./Files_to_submit/data/q1/yelp-vocab.txt', 'w') as f:\n",
    "    for feature in yelp_feature_set:\n",
    "        word_details = [str(feature[0]), str(feature[1][0]), str(feature[1][1])]\n",
    "        f.write('\\t'.join(word_details))\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./Files_to_submit/data/q1/IMDB-vocab.txt', 'w') as f:\n",
    "    for feature in imdb_feature_set:\n",
    "        word_details = [str(feature[0]), str(feature[1][0]), str(feature[1][1])]\n",
    "        f.write('\\t'.join(word_details))\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_dataset_file(vocab, dataset_df, filename, label_name):\n",
    "    with open('./Files_to_submit/data/q1/' + filename, 'w') as f:\n",
    "        for i in range(len(dataset_df)):\n",
    "            review = dataset_df['review'][i]\n",
    "            word_ids = []\n",
    "            for word in review.split():\n",
    "                if word in vocab:\n",
    "                    word_ids.append(str(int(vocab[word][0])))\n",
    "                    \n",
    "            f.write(' '.join(word_ids))\n",
    "            f.write('\\t' + str(int(dataset_df[label_name][i])))\n",
    "            f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "yelp_dictionary = dict(yelp_feature_set)\n",
    "imdb_dictionary = dict(imdb_feature_set)\n",
    "\n",
    "write_dataset_file(yelp_dictionary, yelp_train_df, 'yelp-train.txt', yelp_columns[1])\n",
    "write_dataset_file(yelp_dictionary, yelp_valid_df, 'yelp-valid.txt', yelp_columns[1])\n",
    "write_dataset_file(yelp_dictionary, yelp_test_df, 'yelp-test.txt', yelp_columns[1])\n",
    "\n",
    "write_dataset_file(imdb_dictionary, imdb_train_df, 'IMDB-train.txt', imdb_columns[1])\n",
    "write_dataset_file(imdb_dictionary, imdb_valid_df, 'IMDB-valid.txt', imdb_columns[1])\n",
    "write_dataset_file(imdb_dictionary, imdb_test_df, 'IMDB-test.txt', imdb_columns[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### PART 2 #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 2.a ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nYelp Random Classifier\\n'"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Yelp Random Classifier\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "yelp_test_random_pred = [randint(1,5) for i in range(len(yelp_test_output))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "yelp_test_random_f1_score = f1_score(yelp_test_output, yelp_test_random_pred, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/papermill.record+json": {
       "2a. Yelp Random F1": "0.18063884564391097"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pm.record(\"2a. Yelp Random F1\", str(yelp_test_random_f1_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nYelp Majority Classifier\\n'"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Yelp Majority Classifier\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "yelp_train_majority = mode(yelp_train_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "yelp_test_majority_pred = [yelp_train_majority for i in range(len(yelp_test_output))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "yelp_test_majority_f1_score = f1_score(yelp_test_output, yelp_test_majority_pred, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.351"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yelp_test_majority_f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/papermill.record+json": {
       "2a. Yelp Majority F1": "0.10392301998519615"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pm.record(\"2a. Yelp Majority F1\", str(yelp_test_majority_f1_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 2.b ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
